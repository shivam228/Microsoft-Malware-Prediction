{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier, forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import copy\n",
    "from mlxtend.classifier import StackingCVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainPreprocessed_hot.csv')\n",
    "test = pd.read_csv('testPreprocessed_hot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['HasDetections'].copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training----------- \n",
    "# using stacking Auc Score = 0.717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.LGBMClassifier(objective = 'binary',\n",
    "        boosting_type = 'gbdt',\n",
    "        n_estimators = 2000,\n",
    "        learning_rate = 0.02, \n",
    "        num_leaves = 50,\n",
    "        min_data_in_leaf = 125, \n",
    "        bagging_fraction = 0.901,\n",
    "        max_depth = 13, \n",
    "        reg_alpha = 2.5,\n",
    "        reg_lambda = 2.5,\n",
    "        min_split_gain = 0.0001,\n",
    "        min_child_weight = 25,\n",
    "        feature_fraction = 0.5, \n",
    "        silent = -1,\n",
    "        verbose = -1,\n",
    "        class_weight='balanced',\n",
    "        n_jobs = -1)\n",
    "model2 = RandomForestClassifier(n_estimators=1000, min_samples_leaf=30,min_samples_split= 2, n_jobs=-1, oob_score=False, class_weight='balanced')\n",
    "model3 = DecisionTreeClassifier(min_samples_leaf=40, max_depth=15,min_samples_split = 3, class_weight='balanced')\n",
    "model = lgb.LGBMClassifier(class_weight='balanced',n_jobs = -1)\n",
    "sclf = StackingCVClassifier(classifiers=[model1, model2, model3], meta_classifier=model, use_probas=True, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingCVClassifier(classifiers=[LGBMClassifier(bagging_fraction=0.901,\n",
       "                                                 class_weight='balanced',\n",
       "                                                 feature_fraction=0.5,\n",
       "                                                 learning_rate=0.02,\n",
       "                                                 max_depth=13,\n",
       "                                                 min_child_weight=25,\n",
       "                                                 min_data_in_leaf=125,\n",
       "                                                 min_split_gain=0.0001,\n",
       "                                                 n_estimators=2000,\n",
       "                                                 num_leaves=50,\n",
       "                                                 objective='binary',\n",
       "                                                 reg_alpha=2.5, reg_lambda=2.5,\n",
       "                                                 silent=-1, verbose=-1),\n",
       "                                  RandomForestClassifier(class_weight='balanced',\n",
       "                                                         min_samples_leaf=30,\n",
       "                                                         n_estimators=1000,\n",
       "                                                         n_jobs=-1),\n",
       "                                  DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                         max_depth=15,\n",
       "                                                         min_samples_leaf=40,\n",
       "                                                         min_samples_split=3)],\n",
       "                     cv=3,\n",
       "                     meta_classifier=LGBMClassifier(class_weight='balanced'),\n",
       "                     use_probas=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predprobs = model.predict_proba(X_test)\n",
    "predprobs = predprobs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test1 = pd.read_csv(\"test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = temp_test1['MachineIdentifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'MachineIdentifier':k,'HasDetections':predprobs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'new_sub9.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " using stacking we were able to achieve Auc score = 0.717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end-------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
